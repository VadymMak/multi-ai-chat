"""
VS Code Extension API endpoints.
Full Smart Context using EXISTING services:
- build_smart_context() from smart_context.py
- MemoryManager from manager.py
- store_message_with_embedding() from vector_service.py
"""
from typing import Optional, List, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy import text
from pydantic import BaseModel
from uuid import uuid4
import json
import re
import difflib

from app.deps import get_current_active_user, get_db
from app.memory.models import User, Role, Project
from app.memory.manager import MemoryManager
from app.providers.factory import ask_model
from app.utils.api_key_resolver import get_openai_key
from app.services.smart_context import build_smart_context
from app.services.vector_service import store_message_with_embedding

router = APIRouter(prefix="/vscode", tags=["vscode"])

def normalize_code(text: str) -> str:
    """
    Normalize code for better SEARCH/REPLACE matching.
    Removes trailing whitespace and empty lines at start/end.
    """
    if not text:
        return text
    
    # Split into lines
    lines = text.split('\n')
    
    # Remove trailing whitespace from each line
    lines = [line.rstrip() for line in lines]
    
    # Remove empty lines at start
    while lines and not lines[0].strip():
        lines.pop(0)
    
    # Remove empty lines at end
    while lines and not lines[-1].strip():
        lines.pop()
    
    return '\n'.join(lines)


# Request/Response Models
class VSCodeChatRequest(BaseModel):
    message: str
    project_id: Optional[int] = None
    role_id: Optional[int] = None
    chat_session_id: Optional[str] = None
    filePath: Optional[str] = None
    fileContent: Optional[str] = None
    selectedText: Optional[str] = None
    mode: Optional[str] = None


class VSCodeChatResponse(BaseModel):
    message: str
    chat_session_id: Optional[str] = None
    response_type: str = "chat"  
    original_content: Optional[str] = None  
    new_content: Optional[str] = None  
    diff: Optional[str] = None  
    file_path: Optional[str] = None  
    tokens_used: Optional[Dict[str, int]] = None  


class EditFileRequest(BaseModel):
    project_id: int
    file_path: str
    instruction: str
    current_content: str


class CreateFileRequest(BaseModel):
    project_id: int
    instruction: str
    file_path: Optional[str] = None
    current_content: Optional[str] = None


async def classify_user_intent(
    message: str,
    has_file_open: bool,
    user_api_key: str
) -> str:
    """
    Classify user intent using GPT-4o-mini.
    
    Returns: "EDIT", "CREATE", or "CHAT"
    Cost: ~$0.0001 (very cheap!)
    """
    
    prompt = f"""Classify this user message into ONE category:

Message: "{message}"
File is currently open: {has_file_open}

Categories:
- EDIT: User wants to modify/change/fix/refactor/add to existing code in the open file
  Examples: "add error handling", "fix this bug", "refactor to async", "optimize this"
  
- CREATE: User wants to create/build/make a new file/component/class
  Examples: "create a UserService", "make a login component", "build an API client"
  
- CHAT: User wants explanation/discussion/help/information
  Examples: "explain this code", "what does this do", "why use async", "how does this work"

Rules:
- If file is open AND message asks to change it â†’ EDIT
- If message asks to create something new â†’ CREATE  
- Otherwise â†’ CHAT

Respond with ONLY one word: EDIT, CREATE, or CHAT"""

    try:
        classification = ask_model(
            messages=[{"role": "user", "content": prompt}],
            model_key="gpt-4o-mini",
            temperature=0.1,
            max_tokens=10,
            api_key=user_api_key
        )
        
        result = classification.strip().upper()
        
        # Validate result
        if result in ["EDIT", "CREATE", "CHAT"]:
            print(f"ğŸ¯ [Intent] '{message[:50]}...' â†’ {result}")
            return result
        else:
            print(f"âš ï¸ [Intent] Invalid classification '{result}', defaulting to CHAT")
            return "CHAT"
            
    except Exception as e:
        print(f"âš ï¸ [Intent] Classification failed: {e}, defaulting to CHAT")
        return "CHAT"


async def edit_file_with_ai(
    request: EditFileRequest, 
    current_user: User, 
    db: Session
):
    """
    Edit file using AI with Smart Context.
    Returns diff between original and new content.
    """
    try:
        print(f"\nğŸ”§ [EDIT] file={request.file_path}")
        print(f"ğŸ“ [EDIT] instruction: {request.instruction[:100]}...")
        
        # Get user's API key
        user_api_key = get_openai_key(current_user, db, required=True)
        
        # Initialize memory
        memory = MemoryManager(db)
        
        # âœ… ĞĞĞ’ĞĞ•: Ğ”Ğ»Ñ EDIT mode ĞĞ• Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Smart Context
        # ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: Smart Context Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ ĞºĞ¾Ğ´ Ğ¸Ğ· Ğ”Ğ Ğ£Ğ“Ğ˜Ğ¥ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²,
        # AI Ğ¿ÑƒÑ‚Ğ°ĞµÑ‚ÑÑ Ğ¸ Ğ¸Ñ‰ĞµÑ‚ ĞºĞ¾Ğ´ Ğ½Ğµ Ğ² Ñ‚Ğ¾Ğ¼ Ñ„Ğ°Ğ¹Ğ»Ğµ!
        
        # Ğ’Ğ¼ĞµÑÑ‚Ğ¾ Smart Context Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¢ĞĞ›Ğ¬ĞšĞ recent messages
        try:
            recent_msgs = memory.get_recent_messages(
                role_id=1,
                project_id=str(request.project_id),
                session_id=str(uuid4()),
                limit=3,
                for_display=False
            )
            
            if recent_msgs:
                context = "Recent conversation:\n"
                for msg in recent_msgs:
                    context += f"[{msg.sender}]: {msg.text[:200]}...\n"
            else:
                context = "No recent conversation."
                
        except Exception as e:
            print(f"âš ï¸ [EDIT] Could not load recent messages: {e}")
            context = "No context available."
        
        print(f"ğŸ“‹ [EDIT] Context length: {len(context)} chars")
        print(f"ğŸ“‹ [EDIT] Context preview: {context[:300]}...")

        original_lines = request.current_content.count('\n') + 1
        original_chars = len(request.current_content)
        
        # Build prompt
        # Build prompt with STRICT formatting rules
        prompt = f"""You are an expert code editor. Your ONLY job is to provide SEARCH/REPLACE instructions.

CURRENT FILE: {request.file_path}
Lines: {original_lines} | Characters: {original_chars}

=== FILE CONTENT ===
{request.current_content}

=== USER INSTRUCTION ===
{request.instruction}

=== PROJECT CONTEXT ===
{context}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CRITICAL FORMAT RULES - FOLLOW EXACTLY:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. âŒ DO NOT use markdown (no ```python or ```)
2. âŒ DO NOT add headers like "### SEARCH/REPLACE 1"
3. âŒ DO NOT add explanations before/after
4. âœ… USE ONLY this EXACT format:

SEARCH:
<<<
[exact code from file - copy character-for-character]
>>>

REPLACE:
<<<
[modified code with your changes]
>>>

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
SEARCH BLOCK RULES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Copy EXACT text from file (character-for-character)
2. Include 5-10 lines of context (not more!)
3. Keep ALL whitespace, indentation, quotes EXACTLY as in file
4. If code has multiple locations - provide ONE block for MAIN location only
5. Test mentally: Can I find this EXACT text in file above? If NO - try again!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
EXAMPLE (CORRECT):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SEARCH:
<<<
    def get_user_by_id(self, user_id):
        
        if user_id in self.cache:
            return self.cache[user_id]
        query = f"SELECT * FROM users WHERE id = {{user_id}}"
        result = self.db.execute(query)
>>>

REPLACE:
<<<
    def get_user_by_id(self, user_id):
        
        try:
            if user_id in self.cache:
                return self.cache[user_id]
            query = f"SELECT * FROM users WHERE id = {{user_id}}"
            result = self.db.execute(query)
            return result
        except Exception as e:
            raise Exception(f"Failed to get user {{user_id}}: {{e}}")
>>>

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
NOW GENERATE YOUR SEARCH/REPLACE BLOCKS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Focus on: {request.instruction}
Provide 1-2 SEARCH/REPLACE blocks maximum.
Response must start with "SEARCH:" immediately.
"""
        
        # Dynamic max_tokens calculation
        estimated_tokens = original_chars // 4
        max_tokens_needed = int(estimated_tokens * 2.0)
        max_tokens_needed = min(max_tokens_needed, 16000)
        max_tokens_needed = max(max_tokens_needed, 6000)

        print(f"ğŸ¯ [EDIT] Using max_tokens={max_tokens_needed} for file with {original_chars} chars")

        # Call AI
        ai_response = ask_model(
            messages=[
                {"role": "system", "content": "You are an expert code editor that provides precise SEARCH/REPLACE instructions."},
                {"role": "user", "content": prompt}
            ],
            model_key="gpt-4o",
            temperature=0.2,
            max_tokens=max_tokens_needed,  # Smaller since only changes
            api_key=user_api_key
        )

        response_text = ai_response.strip()
        print(f"\n{'='*80}")
        print(f"ğŸ¤– [AI RESPONSE] Length: {len(response_text)} chars")
        print(f"ğŸ¤– [AI RESPONSE] First 500 chars:")
        print(response_text[:500])
        print(f"{'='*80}\n")

        # âœ… ĞĞĞ’ĞĞ•: Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ Ñ fallback
        
        # Ğ¨Ğ°Ğ³ 1: Ğ£Ğ±Ñ€Ğ°Ñ‚ÑŒ markdown ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
        cleaned_text = response_text
        cleaned_text = re.sub(r'```python\s*', '', cleaned_text)
        cleaned_text = re.sub(r'```typescript\s*', '', cleaned_text)
        cleaned_text = re.sub(r'```\s*', '', cleaned_text)
        cleaned_text = re.sub(r'#{1,6}\s+.*?\n', '', cleaned_text)  #