"""
VS Code Extension API endpoints.
Full Smart Context using EXISTING services:
- build_smart_context() from smart_context.py
- MemoryManager from manager.py
- store_message_with_embedding() from vector_service.py
"""
from typing import Optional, List, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy import text
from pydantic import BaseModel
from uuid import uuid4
import json
import re
import difflib

from app.deps import get_current_active_user, get_db
from app.memory.models import User, Role, Project
from app.memory.manager import MemoryManager
from app.providers.factory import ask_model
from app.utils.api_key_resolver import get_openai_key
from app.services.smart_context import build_smart_context
from app.services.vector_service import store_message_with_embedding

router = APIRouter(prefix="/vscode", tags=["vscode"])


# Request/Response Models
class VSCodeChatRequest(BaseModel):
    message: str
    project_id: Optional[int] = None
    role_id: Optional[int] = None
    chat_session_id: Optional[str] = None
    filePath: Optional[str] = None
    fileContent: Optional[str] = None
    selectedText: Optional[str] = None


class VSCodeChatResponse(BaseModel):
    message: str
    chat_session_id: Optional[str] = None
    response_type: str = "chat"  
    original_content: Optional[str] = None  
    new_content: Optional[str] = None  
    diff: Optional[str] = None  
    file_path: Optional[str] = None  
    tokens_used: Optional[Dict[str, int]] = None  


class EditFileRequest(BaseModel):
    project_id: int
    file_path: str
    instruction: str
    current_content: str


class CreateFileRequest(BaseModel):
    project_id: int
    instruction: str
    file_path: Optional[str] = None
    current_content: Optional[str] = None


async def classify_user_intent(
    message: str,
    has_file_open: bool,
    user_api_key: str
) -> str:
    """
    Classify user intent using GPT-4o-mini.
    
    Returns: "EDIT", "CREATE", or "CHAT"
    Cost: ~$0.0001 (very cheap!)
    """
    
    prompt = f"""Classify this user message into ONE category:

Message: "{message}"
File is currently open: {has_file_open}

Categories:
- EDIT: User wants to modify/change/fix/refactor/add to existing code in the open file
  Examples: "add error handling", "fix this bug", "refactor to async", "optimize this"
  
- CREATE: User wants to create/build/make a new file/component/class
  Examples: "create a UserService", "make a login component", "build an API client"
  
- CHAT: User wants explanation/discussion/help/information
  Examples: "explain this code", "what does this do", "why use async", "how does this work"

Rules:
- If file is open AND message asks to change it ‚Üí EDIT
- If message asks to create something new ‚Üí CREATE  
- Otherwise ‚Üí CHAT

Respond with ONLY one word: EDIT, CREATE, or CHAT"""

    try:
        classification = ask_model(
            messages=[{"role": "user", "content": prompt}],
            model_key="gpt-4o-mini",
            temperature=0.1,
            max_tokens=10,
            api_key=user_api_key
        )
        
        result = classification.strip().upper()
        
        # Validate result
        if result in ["EDIT", "CREATE", "CHAT"]:
            print(f"üéØ [Intent] '{message[:50]}...' ‚Üí {result}")
            return result
        else:
            print(f"‚ö†Ô∏è [Intent] Invalid classification '{result}', defaulting to CHAT")
            return "CHAT"
            
    except Exception as e:
        print(f"‚ö†Ô∏è [Intent] Classification failed: {e}, defaulting to CHAT")
        return "CHAT"


async def edit_file_with_ai(
    request: EditFileRequest, 
    current_user: User, 
    db: Session
):
    """
    Edit file using AI with Smart Context.
    Returns diff between original and new content.
    """
    try:
        print(f"\nüîß [EDIT] file={request.file_path}")
        print(f"üìù [EDIT] instruction: {request.instruction[:100]}...")
        
        # Get user's API key
        user_api_key = get_openai_key(current_user, db, required=True)
        
        # Initialize memory
        memory = MemoryManager(db)
        
        # Build Smart Context
        context = await build_smart_context(  # ‚Üê async!
            project_id=request.project_id,
            role_id=1,  # default role
            query=request.instruction,
            session_id=str(uuid4()),  # –≤—Ä–µ–º–µ–Ω–Ω—ã–π session
            db=db,
            memory=memory  # —É–∂–µ –µ—Å—Ç—å –≤—ã—à–µ!
        )

        original_lines = request.current_content.count('\n') + 1
        original_chars = len(request.current_content)
        
        # Build prompt
        prompt = f"""You are an expert code editor. You need to add the requested changes to a specific location in the file.

CURRENT FILE ({request.file_path}):
Total lines: {original_lines}
Total characters: {original_chars}

FILE CONTENT:
{request.current_content}

INSTRUCTION:
{request.instruction}

PROJECT CONTEXT:
{context}

TASK:
Identify the EXACT location(s) where changes should be made and provide them in SEARCH/REPLACE format.

FORMAT - Use this EXACT format:

SEARCH:
<<<
[exact code to find - must match character-for-character]
>>>

REPLACE:
<<<
[new code with your changes]
>>>

RULES:
1. The SEARCH block must be EXACT - copy it character-for-character from the file
2. Include enough context (5-10 lines) to uniquely identify the location
3. The REPLACE block should have the same structure with your changes
4. You can provide multiple SEARCH/REPLACE pairs if needed
5. Keep indentation identical
6. Do NOT modify anything outside SEARCH/REPLACE blocks
7. Do NOT use markdown code blocks like ```python

EXAMPLE:

SEARCH:
<<<
async def edit_file_with_ai(
    request: EditFileRequest, 
    current_user: User, 
    db: Session
):
    try:
        print(f"File: {{request.file_path}}")
>>>

REPLACE:
<<<
async def edit_file_with_ai(
    request: EditFileRequest, 
    current_user: User, 
    db: Session
):
    try:
        print(f"File: {{request.file_path}}")
    except Exception as e:
        logger.error(f"Edit failed: {{str(e)}}")
        raise HTTPException(500, detail=str(e))
>>>

Now provide the SEARCH/REPLACE blocks for: {request.instruction}"""
        
        # Dynamic max_tokens calculation
        estimated_tokens = original_chars // 4
        max_tokens_needed = int(estimated_tokens * 2.0)
        max_tokens_needed = min(max_tokens_needed, 16000)
        max_tokens_needed = max(max_tokens_needed, 6000)

        print(f"üéØ [EDIT] Using max_tokens={max_tokens_needed} for file with {original_chars} chars")

        # Call AI
        ai_response = ask_model(
            messages=[
                {"role": "system", "content": "You are an expert code editor that provides precise SEARCH/REPLACE instructions."},
                {"role": "user", "content": prompt}
            ],
            model_key="gpt-4o",
            temperature=0.2,
            max_tokens=2000,  # Smaller since only changes
            api_key=user_api_key
        )

        response_text = ai_response.strip()

        # Parse SEARCH/REPLACE blocks
        search_replace_pattern = r'SEARCH:\s*<<<\s*(.*?)\s*>>>\s*REPLACE:\s*<<<\s*(.*?)\s*>>>'
        matches = re.findall(search_replace_pattern, response_text, re.DOTALL)

        if not matches:
            # Fallback: AI didn't follow format
            print(f"‚ö†Ô∏è [EDIT] AI response didn't follow SEARCH/REPLACE format")
            print(f"   Response: {response_text[:200]}...")
            raise HTTPException(
                status_code=400,
                detail="AI response didn't follow SEARCH/REPLACE format. Please try again with a more specific instruction."
            )

        # Apply all SEARCH/REPLACE operations
        new_content = request.current_content

        for i, (search_block, replace_block) in enumerate(matches):
            search_text = search_block.strip()
            replace_text = replace_block.strip()
            
            print(f"üîç [EDIT] Processing replacement {i+1}/{len(matches)}")
            print(f"   Searching for: {len(search_text)} chars")
            
            # Check if search text exists in file
            if search_text not in new_content:
                print(f"‚ö†Ô∏è [EDIT] Search block not found in file:")
                print(f"   Looking for: {search_text[:200]}...")
                raise HTTPException(
                    status_code=400,
                    detail=f"Could not find the code block to replace (block {i+1}). The AI may have made a mistake. Please try again."
                )
            
            # Replace once (first occurrence)
            new_content = new_content.replace(search_text, replace_text, 1)
            print(f"‚úÖ [EDIT] Applied replacement {i+1}: {len(search_text)} ‚Üí {len(replace_text)} chars")

        # Generate diff
        diff = ''.join(difflib.unified_diff(
            request.current_content.splitlines(keepends=True),
            new_content.splitlines(keepends=True),
            fromfile=f"a/{request.file_path}",
            tofile=f"b/{request.file_path}",
            lineterm=''
        ))

        print(f"‚úÖ [EDIT] Generated changes: {len(matches)} replacements, {len(diff)} chars diff")

        # Return response
        return type('obj', (object,), {
            'original_content': request.current_content,
            'new_content': new_content,
            'diff': diff,
            'tokens_used': {'total': len(prompt.split()) + len(response_text.split())}
        })()
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå [EDIT] Failed: {e}")
        raise


async def create_file_with_ai(
    request: CreateFileRequest, 
    current_user: User, 
    db: Session
):
    """
    Create new file using AI with Smart Context.
    Suggests filename if not provided.
    """
    try:
        print(f"\nüìù [CREATE] instruction: {request.instruction[:100]}...")
        
     