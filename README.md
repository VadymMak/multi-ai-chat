# Multi-AI Assistant

A full-stack AI assistant app that integrates multiple AI providers, role-based memory, file upload support, and research tools like YouTube and web search. Built as a modern training project to learn FastAPI, React, and multi-model orchestration.

---

## ðŸŒ Live Demo

Frontend deployed at: [https://multi-llm-chat.netlify.app](https://multi-llm-chat.netlify.app)

---

## ðŸ—‚ï¸ Project Structure

```
multi-ai-assistant/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py               # Entry point for FastAPI
â”‚   â”‚   â”œâ”€â”€ api/                  # Routes (e.g., ask, ask-ai-to-ai, upload)
â”‚   â”‚   â”œâ”€â”€ providers/            # Model providers: openai, claude, grok
â”‚   â”‚   â”œâ”€â”€ memory/               # Memory manager, token utils, memory DB
â”‚   â”‚   â”œâ”€â”€ services/             # YouTube, Wikipedia/web search integrations
â”‚   â”‚   â””â”€â”€ utils/                # Prompt templates, helpers, logging
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/           # ChatArea, InputBar, Header, RoleSelector, etc.
â”‚   â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”‚   â””â”€â”€ aiConversation/   # Main chat view logic (AiChat.tsx)
â”‚   â”‚   â”œâ”€â”€ store/                # Zustand stores for chat, model, project, memory
â”‚   â”‚   â”œâ”€â”€ services/             # Axios API wrappers
â”‚   â”‚   â”œâ”€â”€ styles/               # Tailwind CSS + custom styles
â”‚   â”‚   â””â”€â”€ App.tsx / index.tsx
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ README.md (this file)
â””â”€â”€ .env, .gitignore, Dockerfile (coming soon)
```

---

## ðŸš€ Features

- âœ… OpenAI, Claude, and xAI Grok support
- âœ… Boost Mode: AI-to-AI review flow
- âœ… Role & Project-based long-term memory
- âœ… Document upload with OCR and summarization
- âœ… YouTube + Wikipedia search integration
- âœ… Prompt injection with custom variables
- âœ… Typing animation and streaming responses
- âœ… Tailwind-styled React frontend
- âœ… FastAPI backend with modular structure

---

## ðŸ›  Getting Started (Backend)

```bash
# Navigate to backend directory
cd backend

# Create and activate virtual environment
python -m venv llm_env
source llm_env/bin/activate  # or .\llm_env\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Run server
uvicorn app.main:app --reload
```

> ðŸ“Œ Configure `.env` file with your OpenAI, Anthropic, and YouTube API keys.

---

## ðŸ’¬ Getting Started (Frontend)

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

> Tailwind CSS is configured manually and loaded via `src/styles/tailwind.css`.

---

## ðŸ“¦ Deployment

- Frontend: **Netlify** (`https://multi-llm-chat.netlify.app`)
- Backend: _(TBD: Planning for Docker + Railway/Render/EC2)_

---

## ðŸ§ª Tech Stack

- **Frontend:** React + TypeScript + Zustand + Axios + Tailwind CSS
- **Backend:** FastAPI + SQLite (local), PostgreSQL-ready
- **AI Providers:** OpenAI, Claude (Anthropic), Grok (xAI)
- **File Support:** PDF, DOCX, CSV, TXT, Markdown, Images (with OCR)

---

## ðŸ“š Learning Focus

This is a training project to learn:

- Modular Python with FastAPI
- Multi-model orchestration
- Context-aware memory storage
- Full-stack AI assistant deployment
- Prompt engineering and UX for LLMs

---

## ðŸ§  Want to Extend?

Planned / optional features:

- [ ] Authentication with Supabase/Auth.js
- [ ] Persistent chat sessions with DB
- [ ] Model usage logging and analytics
- [ ] Admin dashboard and prompt metrics
- [ ] Export summaries as Markdown or PDF

---

## ðŸ“„ License

MIT â€“ Use freely and fork to learn or build your own AI agent!
